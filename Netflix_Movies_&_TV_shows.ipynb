{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNIq0CdBLO9XZIlawRtksRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamini262/Netflix-movies-and-tv-shows/blob/main/Netflix_Movies_%26_TV_shows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **\"Hello, I am Kamini Singh. I've meticulously crafted this insightful project, independently exploring Netflix content clustering. Enjoy the journey!\"**\n"
      ],
      "metadata": {
        "id": "RfguiRC8XoCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Netflix Movies and Tv shows clustering Analysis**\n"
      ],
      "metadata": {
        "id": "k24EJba8Dyu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Title: Exploring Netflix Content Trends and Insights**"
      ],
      "metadata": {
        "id": "K9GQUiOJiwOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The world of streaming entertainment has witnessed remarkable growth and transformation in recent years. With the advent of platforms like Netflix, the landscape of content consumption has evolved significantly. This project aims to delve into the intriguing world of Netflix content by analyzing a dataset containing TV shows and movies available on the platform as of 2019. This dataset, sourced from a third-party Netflix search engine called \"Fliable,\" provides a wealth of information about the content available on Netflix and its evolution over the past decade.\n"
      ],
      "metadata": {
        "id": "Y6pT577ui-H1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Objectives"
      ],
      "metadata": {
        "id": "ZEXQwWNxEMRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "GZ8nbd5HEb1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Exploratory Data Analysis (EDA): The project begins with a comprehensive exploration of the dataset. Through data manipulation, aggregation, and visualization using libraries such as Pandas, Matplotlib, and Seaborn, we will gain insights into the dataset's structure and characteristics"
      ],
      "metadata": {
        "id": "ZxNtbHSBEqit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Content Trends Across Countries: **"
      ],
      "metadata": {
        "id": "V8ipU12AEwx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The project seeks to understand the types of content available in different countries. By grouping and analyzing content based on production country, we aim to uncover geographical preferences and trends."
      ],
      "metadata": {
        "id": "0lBQP8CKEzl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Focus on TV vs Movies:***"
      ],
      "metadata": {
        "id": "Tf61qwAJE-3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An essential aspect of this project is to investigate whether Netflix has shifted its focus from movies to TV shows in recent years. By analyzing the growth of TV shows and movies over the past decade, we aim to discern any underlying patterns."
      ],
      "metadata": {
        "id": "aY9KsX5sFH0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering Similar Content**"
      ],
      "metadata": {
        "id": "QdcU_6giFNsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ": Utilizing text-based features like titles, directors, and genres, we will employ clustering techniques to group similar content together. This will offer a unique perspective on content categorization and may reveal hidden patterns"
      ],
      "metadata": {
        "id": "wTTikqSCFbF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Integration with External Ratings**"
      ],
      "metadata": {
        "id": "f59m4pZxFdS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " To enrich our analysis, we plan to integrate external datasets such as IMDb ratings and Rotten Tomatoes scores. By merging these datasets with our Netflix content data, we can uncover interesting correlations and insights"
      ],
      "metadata": {
        "id": "pK2T-vKJFs_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expected Outcomes:**"
      ],
      "metadata": {
        "id": "uWEhtp_OFusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Throughout this project, we aim to not only gain insights into Netflix's content strategy and user preferences but also to demonstrate the power of data analysis in deciphering complex trends. The project's deliverables will include a comprehensive Jupyter Notebook showcasing our code, visualizations, and interpretations. Additionally, a video presentation will be created to succinctly present the key findings and insights to stakeholders."
      ],
      "metadata": {
        "id": "jdzxlxknFprs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Significance to Stakeholders:"
      ],
      "metadata": {
        "id": "4xPE4WPIF8aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stakeholders in the entertainment industry, content creators, and streaming platforms can greatly benefit from the insights provided by this project. By understanding content trends, user preferences, and the impact of external ratings, stakeholders can make informed decisions about content production, licensing, and audience targeting."
      ],
      "metadata": {
        "id": "D5aUednaGG3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Skills and Tools:**"
      ],
      "metadata": {
        "id": "29C39ieBGEHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project will be implemented using Python programming and popular libraries such as Pandas, Matplotlib, Seaborn, and Scikit-learn. We will leverage data manipulation, visualization, and clustering techniques to achieve our objectives."
      ],
      "metadata": {
        "id": "EJAouHiIGPD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis (EDA) steps using Python code:**\n"
      ],
      "metadata": {
        "id": "WOasxmz7kD3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "0xvRcGEUkN8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YhC2wkWDIqx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "\n",
        "# Read the CSV file using pandas\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "GksmSHEtI8kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "uxbVG7KxJgRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geting all the values of the  data\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "tk1gS_V9JVVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Path to the CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Get the index of the DataFrame\n",
        "index_values = data.index\n",
        "\n",
        "# Display the index values\n",
        "print(index_values)"
      ],
      "metadata": {
        "id": "X76_C2GrJxdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand the basic structure of the dataset\n",
        "print(data.info())\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "uMLc8KYfpccZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for missing values\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "id": "QfAwQ1afpiY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for missing values\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "id": "JabViip-pjU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Release year distribution\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.histplot(data=data, x=\"release_year\", bins=20)\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.title(\"Distribution of Release Years\")"
      ],
      "metadata": {
        "id": "5qJ1fgoopvOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Duration distribution\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.histplot(data=data, x=\"duration\", bins=20)\n",
        "plt.xlabel(\"Duration (minutes)\")\n",
        "plt.title(\"Distribution of Durations\")"
      ],
      "metadata": {
        "id": "gpTCwpbdpw-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Release year distribution\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.histplot(data=data, x=\"release_year\", bins=20)\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.title(\"Distribution of Release Years\")"
      ],
      "metadata": {
        "id": "n8DS5SL3p3HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Content type distribution (TV shows vs. Movies)\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.countplot(data=data, x=\"type\")\n",
        "plt.xlabel(\"Content Type\")\n",
        "plt.title(\"Distribution of Content Types\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aaSx0g6UqZN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the distribution of TV shows and movies over the years\n",
        "content_by_year = data.groupby(\"release_year\")[\"type\"].value_counts().unstack()\n",
        "content_by_year.plot(kind=\"bar\", stacked=True)\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Content Distribution: TV Shows vs. Movies\")\n",
        "plt.legend(title=\"Content Type\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MZynyegWqjgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the most common genres, directors, actors, and countries\n",
        "top_genres = data[\"listed_in\"].str.split(\", \").explode().value_counts().head(10)\n",
        "top_directors = data[\"director\"].value_counts().head(10)\n",
        "top_actors = data[\"cast\"].str.split(\", \").explode().value_counts().head(10)\n",
        "top_countries = data[\"country\"].value_counts().head(10)"
      ],
      "metadata": {
        "id": "bU0H8CVVqq8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Visualize top genres of the movies\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x=top_genres.values, y=top_genres.index)\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Genre\")\n",
        "plt.title(\"Top 10 Genres\")"
      ],
      "metadata": {
        "id": "8_M1JUPcKDZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the top Director of the Movies\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x=top_directors.values, y=top_directors.index)\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Director\")\n",
        "plt.title(\"Top 10 Directors\")"
      ],
      "metadata": {
        "id": "Tke1KMA8KMhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Top 10 Actors of the Movies sets\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=top_actors.values, y=top_actors.index)\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Actor\")\n",
        "plt.title(\"Top 10 Actors\")"
      ],
      "metadata": {
        "id": "9WbMb-lTKYV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the  top cuntries\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=top_actors.values, y=top_actors.index)\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"countries\")\n",
        "plt.title(\"Top 10 countries\")"
      ],
      "metadata": {
        "id": "tQKNwOB6KicM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine correlations between variables\n",
        "correlation_matrix = data.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dpBBD7qq4Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of content types\n",
        "content_type_counts = data['type'].value_counts()\n",
        "plt.bar(content_type_counts.index, content_type_counts.values)\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Content Types')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7eZGIS9NOSbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text data processing**"
      ],
      "metadata": {
        "id": "dZwEsZ1_OeW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data load and processing\n",
        "# Load the dataset\n",
        "csv_file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Display the first few rows after preprocessing\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "Ly_DF-6dQIaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess text features\n",
        "text_features = ['title', 'director', 'cast', 'listed_in', 'description']\n",
        "for feature in text_features:\n",
        "    data[feature].fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "Cv1LqL5uQIXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "csv_file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the dataset before preprocessing\n",
        "print(\"Before Preprocessing:\")\n",
        "print(data.head())\n",
        "\n",
        "# Preprocess text features\n",
        "text_features = ['title', 'director', 'cast', 'listed_in', 'description']\n",
        "for feature in text_features:\n",
        "    data[feature].fillna('', inplace=True)\n",
        "\n",
        "# Display the first few rows of the dataset after preprocessing\n",
        "print(\"After Preprocessing:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "67hhMstqSdle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "csv_file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Preprocess text features\n",
        "text_features = ['title', 'director', 'cast', 'listed_in', 'description']\n",
        "for feature in text_features:\n",
        "    data[feature].fillna('', inplace=True)\n",
        "\n",
        "# Combine text features into a single column\n",
        "data['combined_text'] = data[text_features].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "# TF-IDF vectorization for text features\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['combined_text'])\n",
        "\n",
        "# Convert the sparse matrix to dense array\n",
        "tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "# Agglomerative Hierarchical Clustering\n",
        "agg_clustering = AgglomerativeClustering(n_clusters=5)\n",
        "data['agg_cluster'] = agg_clustering.fit_predict(tfidf_array)\n",
        "\n",
        "# Print unique cluster labels and their distribution\n",
        "print(data['agg_cluster'].value_counts())"
      ],
      "metadata": {
        "id": "ftEinLPYRMnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modeling and clustering though Machine learing algorithm**"
      ],
      "metadata": {
        "id": "ooj4z9pGO2gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "csv_file_path = '/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Preprocess text features\n",
        "text_features = ['title', 'director', 'cast', 'listed_in', 'description']\n",
        "for feature in text_features:\n",
        "    data[feature].fillna('', inplace=True)\n",
        "\n",
        "# Combine text features into a single column\n",
        "data['combined_text'] = data[text_features].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "# TF-IDF vectorization for text features\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['combined_text'])\n",
        "\n",
        "# Convert the sparse TF-IDF matrix to a dense numpy array\n",
        "tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "# K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "data['kmeans_cluster'] = kmeans.fit_predict(tfidf_array)\n",
        "\n",
        "# Agglomerative Hierarchical Clustering\n",
        "agg_clustering = AgglomerativeClustering(n_clusters=5)\n",
        "data['agg_cluster'] = agg_clustering.fit_predict(tfidf_array)\n",
        "\n",
        "# Print unique cluster labels and their distribution\n",
        "print(\"K-Means Cluster Distribution:\")\n",
        "print(data['kmeans_cluster'].value_counts())\n",
        "print(\"\\nAgglomerative Cluster Distribution:\")\n",
        "print(data['agg_cluster'].value_counts())"
      ],
      "metadata": {
        "id": "Ki4YgMK3TSbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram for Numerical Features:\n",
        "Plot histograms to visualize the distribution of numerical features like released year, duration, etc.**"
      ],
      "metadata": {
        "id": "6WA_KnRzT6GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of release year\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['release_year'].hist(bins=30)  # Replace 'released_year' with 'release_year'\n",
        "plt.title('Release Year Distribution')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DC51hL0FTxa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word Clouds for Textual Features:**\n",
        "## Creating word clouds to visualize the most frequent words in descriptions, titles, or other text-based features."
      ],
      "metadata": {
        "id": "q8QJbG9gULxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Word cloud for descriptions\n",
        "plt.figure(figsize=(10, 6))\n",
        "wordcloud = WordCloud(max_words=100, background_color='white').generate(' '.join(data['description']))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud of Descriptions')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Go7k0IrTUQJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Geographical Maps**\n",
        "\n",
        "In the dataset contains country information, I can create a geographical map to show the distribution of content in different countries"
      ],
      "metadata": {
        "id": "yAtj1AD4Uk79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# Load a world map shapefile\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "\n",
        "# Count content by country\n",
        "country_counts = data['country'].value_counts().reset_index()\n",
        "country_counts.columns = ['country', 'count']\n",
        "\n",
        "# Merge data with world map\n",
        "merged = world.merge(country_counts, left_on='name', right_on='country')\n",
        "\n",
        "# Plot map\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
        "world.boundary.plot(ax=ax)\n",
        "merged.plot(column='count', ax=ax, legend=True)\n",
        "plt.title('Content Distribution by Country')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EWyCjklgU0Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cluster Distribution**\n",
        "\n",
        "Displaying the distribution of items across clusters can illustrate how the content has been grouped together based on textual features.**"
      ],
      "metadata": {
        "id": "6Xgdkq3LWiKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "data['kmeans_cluster'].value_counts().sort_index().plot(kind='bar')\n",
        "plt.title('K-Means Cluster Distribution')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AAZXYF2bWaVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "data['agg_cluster'].value_counts().sort_index().plot(kind='bar')\n",
        "plt.title('Agglomerative Cluster Distribution')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oHS6fYdSWdL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Cloud of Clustered Descriptions**\n",
        "\n",
        "\n",
        "For each cluster, you could create a word cloud of the most frequent words in the descriptions to provide a visual representation of the content within each clustet**"
      ],
      "metadata": {
        "id": "XI62uLb_W1AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "for cluster_num in range(5):\n",
        "    cluster_description = ' '.join(data[data['kmeans_cluster'] == cluster_num]['description'])\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(cluster_description)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(f'Cluster {cluster_num} - Word Cloud of Descriptions')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8lH6Zn-4XARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content Type Distribution:\n",
        "A bar plot showing the distribution of content types (movies vs. TV shows) can provide an overview of the dataset's composition.**"
      ],
      "metadata": {
        "id": "QO0gQs65WFUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "rv-h-waFVbxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a summary of the project and its findings\n",
        "print(\"Project Conclusion:\")\n",
        "print(\"------------------------------\")\n",
        "\n",
        "print(\"This project aimed to analyze and cluster Netflix movies and TV shows based on textual features.\")\n",
        "print(\"Key Steps and Findings:\")\n",
        "print(\"- Explored the dataset of Netflix content, understanding its structure and contents.\")\n",
        "print(\"- Conducted exploratory data analysis (EDA) to visualize the distribution of content types, countries, etc.\")\n",
        "print(\"- Preprocessed text-based features, filling missing values and preparing text for analysis.\")\n",
        "print(\"- Performed TF-IDF vectorization to transform text features into a numerical format.\")\n",
        "print(\"- Applied K-Means and Agglomerative Clustering algorithms to cluster similar content.\")\n",
        "print(\"- Visualized the clusters and analyzed their distribution.\")"
      ],
      "metadata": {
        "id": "FINrNYR0Vjjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Provide insights from clustering results\n",
        "print(\"\\nInsights from Clustering:\")\n",
        "print(\"- K-Means and Agglomerative Clustering revealed different clusters of content based on textual features.\")\n",
        "print(\"- Analyzed the distribution of content across clusters to identify patterns and similarities.\")"
      ],
      "metadata": {
        "id": "Z5lQc1PdVot5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discuss potential next steps or improvements\n",
        "print(\"\\nNext Steps and Future Improvements:\")\n",
        "print(\"- Incorporate external datasets (IMDb ratings, Rotten Tomatoes) for more insights.\")\n",
        "print(\"- Experiment with different clustering algorithms and hyperparameters for better results.\")\n",
        "print(\"- Perform deeper analysis on specific clusters to understand their characteristics.\")"
      ],
      "metadata": {
        "id": "hw6aMBdlVssl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thank the readers and conclude\n",
        "print(\"Thank you for following along with this analysis!\")\n",
        "print(\"We appreciate your interest and hope you found the insights and findings valuable.\")\n",
        "print(\"If you have any questions or feedback, please feel free to reach out.\")\n",
        "print(\"------------------------------\")"
      ],
      "metadata": {
        "id": "Ovs3sBm8XdG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}